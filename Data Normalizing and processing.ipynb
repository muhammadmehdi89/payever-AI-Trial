{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85ce2d99",
   "metadata": {},
   "source": [
    "# Data Normalizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa73d3b",
   "metadata": {},
   "source": [
    "# Data Processing and making it ready to use in modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad4ae564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 items from JSON.\n",
      "Processed data contains 4099 items.\n",
      "Saved 4099 rows to normalized_data.csv\n",
      "Data processing and normalization completed. Normalized data saved to normalized_data.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = unicodedata.normalize('NFKD', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.strip()\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def process_paragraphs(paragraphs):\n",
    "    return [normalize_text(paragraph) for paragraph in paragraphs if paragraph]\n",
    "\n",
    "def process_images(images):\n",
    "    return [{'src': image.get('src', ''), 'alt': normalize_text(image.get('alt', ''))} for image in images]\n",
    "\n",
    "def process_sections(sections):\n",
    "    section_data = []\n",
    "    for section in sections:\n",
    "        h2 = section.get('h2', '')\n",
    "        for ul in section.get('uls', []):\n",
    "            if ul:\n",
    "                for link in ul.get('links', []):\n",
    "                    section_data.append({\n",
    "                        'url': link,\n",
    "                        'h1': h2,\n",
    "                        'content_type': 'link',\n",
    "                        'content': link\n",
    "                    })\n",
    "                for paragraph in process_paragraphs(ul.get('text', '').split('\\n')):\n",
    "                    section_data.append({\n",
    "                        'url': '',\n",
    "                        'h1': h2,\n",
    "                        'content_type': 'paragraph',\n",
    "                        'content': paragraph\n",
    "                    })\n",
    "    return section_data\n",
    "\n",
    "\n",
    "def process_additional_data(additional_data):\n",
    "    additional_data_processed = []\n",
    "    for item in additional_data:\n",
    "        url = item.get('url', '')\n",
    "        h1 = item.get('h1', '')\n",
    "        paragraphs = process_paragraphs(item.get('paragraphs', []))\n",
    "        images = process_images(item.get('images', []))\n",
    "        \n",
    "        for paragraph in paragraphs:\n",
    "            additional_data_processed.append({\n",
    "                'url': url,\n",
    "                'h1': h1,\n",
    "                'content_type': 'paragraph',\n",
    "                'content': paragraph\n",
    "            })\n",
    "        for image in images:\n",
    "            additional_data_processed.append({\n",
    "                'url': url,\n",
    "                'h1': h1,\n",
    "                'content_type': 'image',\n",
    "                'content': image['src'],\n",
    "                'alt_text': image['alt']\n",
    "            })\n",
    "    return additional_data_processed\n",
    "\n",
    "def process_data(data):\n",
    "    processed_data = []\n",
    "    # Process sections\n",
    "    sections_data = process_sections(data.get('sections', []))\n",
    "    processed_data.extend(sections_data)\n",
    "    # Process additional data\n",
    "    additional_data = process_additional_data(data.get('additional_data', []))\n",
    "    processed_data.extend(additional_data)\n",
    "    return processed_data\n",
    "\n",
    "def save_to_csv(data, output_file):\n",
    "    if data:\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(output_file, index=False, encoding='utf-8')\n",
    "        print(f\"Saved {len(data)} rows to {output_file}\")\n",
    "    else:\n",
    "        print(\"No data to save.\")\n",
    "\n",
    "def main():\n",
    "    json_file_path = 'scraped_data.json'  \n",
    "    data = load_json(json_file_path)\n",
    "    \n",
    "    # Check if data is loaded correctly\n",
    "    print(f\"Loaded {len(data)} items from JSON.\")\n",
    "    \n",
    "    normalized_data = process_data(data)\n",
    "    \n",
    "    # Check if data is processed correctly\n",
    "    print(f\"Processed data contains {len(normalized_data)} items.\")\n",
    "    \n",
    "    output_csv_path = 'normalized_data.csv'  # Output file path\n",
    "    save_to_csv(normalized_data, output_csv_path)\n",
    "    \n",
    "    print(\"Data processing and normalization completed. Normalized data saved to\", output_csv_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02cefe2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              query                                            context  \\\n",
      "0  Getting Started?  https://support.payever.org/hc/en-us/articles/...   \n",
      "1  Getting Started?  https://support.payever.org/hc/en-us/articles/...   \n",
      "2  Getting Started?  https://support.payever.org/hc/en-us/articles/...   \n",
      "3  Getting Started?  https://support.payever.org/hc/en-us/articles/...   \n",
      "4  Getting Started?  https://support.payever.org/hc/en-us/articles/...   \n",
      "\n",
      "                                            response  \n",
      "0  https://support.payever.org/hc/en-us/articles/...  \n",
      "1  https://support.payever.org/hc/en-us/articles/...  \n",
      "2  https://support.payever.org/hc/en-us/articles/...  \n",
      "3  https://support.payever.org/hc/en-us/articles/...  \n",
      "4  https://support.payever.org/hc/en-us/articles/...  \n",
      "Processed data saved to '/mnt/data/processed_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def load_csv(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data\n",
    "\n",
    "def convert_h1_to_question(h1_text):\n",
    "    # Directly use h1 text as the question without a fixed prefix\n",
    "    question = re.sub(r'[\\W_]+', ' ', h1_text).strip()\n",
    "    question = question + '?'\n",
    "    return question\n",
    "\n",
    "def process_data(csv_file_path):\n",
    "    data = load_csv(csv_file_path)\n",
    "    \n",
    "    questions = []\n",
    "    contexts = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        h1 = row['h1']\n",
    "        content = row['content']\n",
    "        \n",
    "        if pd.notna(h1) and pd.notna(content):\n",
    "            question = convert_h1_to_question(h1)\n",
    "            questions.append(question)\n",
    "            contexts.append(content)\n",
    "    \n",
    "    # Create the DataFrame for training\n",
    "    df = pd.DataFrame({\n",
    "        'query': questions,\n",
    "        'context': contexts,\n",
    "        'response': contexts  # Using context as response for demonstration\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Path to your CSV file\n",
    "csv_file_path = 'normalized_data.csv'\n",
    "processed_df = process_data(csv_file_path)\n",
    "\n",
    "# Display the processed DataFrame\n",
    "print(processed_df.head())\n",
    "\n",
    "# Save processed data to a new CSV file\n",
    "processed_df.to_csv('processed_data.csv', index=False, encoding='utf-8')\n",
    "print(f\"Processed data saved to '/mnt/data/processed_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f5c32e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
